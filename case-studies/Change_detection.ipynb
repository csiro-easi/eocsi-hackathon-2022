{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting change in Malaysian forestry <img align=\"right\" src=\"../resources/csiro_easi_logo.png\">\n",
    "\n",
    "This notebook has been adapted from [Digital Earth Australia](https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/Real_world_examples/Chlorophyll_monitoring.ipynb)\n",
    "* **Products used:** \n",
    "[s2_l2a](http://explorer.asia.easi-eo.solutions/products/s2_l2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Background\n",
    "Methods for detecting meaningful and significant change in forests are important for those who manage and monitor large areas of forest.\n",
    "\n",
    "On-the-ground monitoring can be expensive and time-consuming, especially when forests are in difficult-to-navigate terrain.\n",
    "Aerial photography and LiDAR can provide detailed information about forests, but are often extremely expensive to acquire, even over small areas.\n",
    "\n",
    "### Sentinel-2 use case\n",
    "Satellite imagery from the [EU Copernicus Sentinel-2 mission](https://sentinel.esa.int/web/sentinel/missions/sentinel-2) is freely available.\n",
    "Its 10 metre resolution makes it perfect for monitoring fine changes over very large areas of land.\n",
    "The archive of Sentinel-2 data over Southeast Asia stretches back to 2017, meaning that there is a good amount of data for change detection, allowing us to average out or focus on seasonal changes.\n",
    "\n",
    "## Description\n",
    "In this example, we measure the presence of vegetation from Sentinel-2 imagery and apply a hypothesis test to identify areas of significant change (along with the direction of the change).\n",
    "The worked example takes users through the code required to do the following:\n",
    "\n",
    "1. Load cloud-free Sentinel-2 images for an area of interest\n",
    "2. Compute an index to highlight presence of vegetation (NDVI)\n",
    "3. Apply a statistical hypothesis test to find areas of significant change\n",
    "4. Visualise the statistically significant areas.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "**To run this analysis**, run all the cells in the notebook, starting with the \"Load packages\" cell.\n",
    "\n",
    "**After finishing the analysis**, return to the \"Analysis parameters\" cell, modify some values (e.g. choose a different location or time period to analyse) and re-run the analysis.\n",
    "There are additional instructions on modifying the notebook at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Load key Python packages and any supporting functions for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datacube.utils import masking\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import CRS\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../Tools/')\n",
    "from dea_tools.plotting import rgb, display_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Activate the datacube database, which provides functionality for loading and displaying stored Earth observation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Change_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the length of time to conduct the analysis over.\n",
    "There is also a parameter to define how the data is split in time; the split yields two non-overlapping samples, which is a requirement of the hypothesis test we want to run (more detail below).\n",
    "The parameters are:\n",
    "\n",
    "* `latitude`: The latitude range to analyse (e.g. `(1.2449, 1.195)`).\n",
    "For reasonable loading times, make sure the range spans less than ~0.1 degrees.\n",
    "* `longitude`: The longitude range to analyse (e.g. `(110.5658, 110.6158)`).\n",
    "For reasonable loading times, make sure the range spans less than ~0.1 degrees.\n",
    "* `time`: The date range to analyse (e.g. `('2018-01-01', '2020-12-31')`).\n",
    "Note that Sentinel-2 data is not available in Southeast Asia prior to 2017.\n",
    "For reasonable results, the range should span at least two years to prevent detecting seasonal changes.\n",
    "* `time_baseline`: The date at which to split the total sample into two non-overlapping samples (e.g. `'2019-06-01'`).\n",
    "For reasonable results, pick a date that is about halfway between the start and end dates specified in `time`.\n",
    "\n",
    "**If running the notebook for the first time**, keep the default settings below.\n",
    "This will demonstrate how the analysis works and provide meaningful results.\n",
    "The example covers a commercial plantation located near Serain, Malaysia.\n",
    "\n",
    "**To run the notebook for a different area**, make sure Sentinel-2 data is available for the chosen area using the [EASI CSIRO Asia Explorer](http://explorer.asia.easi-eo.solutions/products/s2_l2a).\n",
    "Use the drop-down menu to check Sentinel-2a and Sentinel-2b (`s2_l2a`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the area of interest\n",
    "longitude = (110.5658, 110.6158)\n",
    "latitude = (1.2449, 1.195)\n",
    "\n",
    "# Set the range of dates for the complete sample\n",
    "time = ('2018-01-01', '2020-12-31')\n",
    "\n",
    "# Set the date to separate the data into two samples for comparison\n",
    "time_baseline = '2019-06-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the selected location\n",
    "The next cell will display the selected area on an interactive map.\n",
    "The red border represents the area of interest of the study.\n",
    "Zoom in and out to get a better understanding of the area of interest.\n",
    "Clicking anywhere on the map will reveal the latitude and longitude coordinates of the clicked point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_map(x=longitude, y=latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view Sentinel-2 data\n",
    "The first step in the analysis is to load Sentinel-2 data for the specified area of interest and time range.\n",
    "\n",
    "The loading process makes use of dask, which will return a lazy-loaded data set. This means that no values will be loaded until abosultely required. As such, the next cell will run quickly, but you won't yet be able to visualise the values.\n",
    "\n",
    "The load is complete when the cell status goes from `[*]` to `[number]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose products to load\n",
    "# Here, the Sentinel-2 product is chosen\n",
    "product = ['s2_l2a']\n",
    "\n",
    "# Specify the parameters to pass to the load query\n",
    "query = {\n",
    "    \"x\": longitude,\n",
    "    \"y\": latitude,\n",
    "    \"time\": time,\n",
    "    \"measurements\": [\n",
    "        \"red\",  # Red band\n",
    "        \"green\",  # Green band\n",
    "        \"blue\",  # Blue band\n",
    "        \"nir_1\",  # Near-infrared band\n",
    "        \"mask\",  # Cloud masking band\n",
    "    ],\n",
    "    \"output_crs\": \"EPSG:3577\",\n",
    "    \"resolution\": (-20, 20),\n",
    "    \"dask_chunks\": {\"time\":1, \"x\":350, \"y\":300}\n",
    "}\n",
    "\n",
    "# Load the data\n",
    "ds_s2 = dc.load(product=product, **query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once the load is complete**, examine the data by printing it in the next cell.\n",
    "The `Dimensions` argument revels the number of time steps in the data set, as well as the number of pixels in the x (longitude) and y (latitude) dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "Clouds, cloud shadows, and other invalid pixels need to be removed before conducting the analysis.\n",
    "\n",
    "The first step in masking is to identify the information in the masking band. This can be done using the `masking.describe_variable_flags)` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking.describe_variable_flags(ds_s2.mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Sentinel-2 in the Asia EASI Hub, the masking information is stored in the **values** column of the **qa** row in this dataframe. To get a better look at the types of pixel classifications this mask has, we can display the values column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking.describe_variable_flags(ds_s2.mask).loc[\"qa\", \"values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now construct a mask of valid pixel classes. In this case, we say that `vegetation`, `bare soils`, `water`, or `snow or ice` are valid, cloud-free pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple flags are combined as logial OR using the | symbol\n",
    "cloud_free_mask = (\n",
    "    masking.make_mask(ds_s2.mask, qa=\"vegetation\") | \n",
    "    masking.make_mask(ds_s2.mask, qa=\"bare soils\") |\n",
    "    masking.make_mask(ds_s2.mask, qa=\"water\") |\n",
    "    masking.make_mask(ds_s2.mask, qa=\"snow or ice\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_free_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a mask that contains the location of valid pixels, we can count the number of valid pixels and divide by the total number of pixels to identify the proportion of valid data in each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportion of good pixels\n",
    "valid_pixel_proportion = cloud_free_mask.sum(dim=(\"x\", \"y\"))/(cloud_free_mask.shape[1] * cloud_free_mask.shape[2])\n",
    "\n",
    "valid_threshold = 0.7\n",
    "observations_to_keep = (valid_pixel_proportion >= valid_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to mask the data, then only keep the observations where more than 70% of the pixels are valid. \n",
    "\n",
    "**Please be patient**. The data may take a few minutes to load and progress will be indicated by text output. The load is complete when the cell status goes from `[*]` to `[number]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the data\n",
    "ds_s2_valid = ds_s2.where(cloud_free_mask)\n",
    "\n",
    "# only keep observations above the good pixel proportion threshold\n",
    "# The .compute() step means the values will be loaded into memory. This step may take some time\n",
    "ds_s2_keep = ds_s2_valid.sel(time=observations_to_keep).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the load is complete, examine the data by printing it in the next cell. The `[Dimensions]` argument reveals the number of time steps in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the loaded data\n",
    "ds_s2_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot example timestep in true colour\n",
    "\n",
    "To visualise the data, use the pre-loaded `rgb` utility function to plot a true colour image for a given time-step.\n",
    "White spots in the images are where clouds have been masked out.\n",
    "\n",
    "The settings below will display images for two time steps, one in mid August 2018, one in early September 2019.\n",
    "Can you spot any areas of change?\n",
    "\n",
    "Feel free to experiement with the values for the `initial_timestep` and `final_timestep` variables; re-run the cell to plot the images for the new timesteps.\n",
    "The values for the timesteps can be `0` to one fewer than the number of time steps loaded in the data set.\n",
    "The number of time steps is the same as the total number of observations listed as the output of the cell used to load the data.\n",
    "\n",
    "> **Note:** If the location and time are changed, you may need to change the `intial_timestep` and `final_timestep` parameters to view images at similar times of year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the timesteps to visualise\n",
    "initial_timestep = 8\n",
    "final_timestep = 19\n",
    "\n",
    "# Generate RGB plots at each timestep\n",
    "rgb(ds_s2_keep, bands=[\"red\", \"green\", \"blue\"], index=[initial_timestep, final_timestep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute band indices\n",
    "This study measures vegetation through the normalised difference vegetation index (NDVI), which can be calculated using the predefined `calculate_indices` utility function.\n",
    "This index uses the ratio of the red and near-infrared (NIR) bands to identify live green vegetation. \n",
    "The formula is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{NDVI} = \\frac{\\text{NIR} - \\text{Red}}{\\text{NIR} + \\text{Red}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "When interpreting this index, high values indicate vegetation, and low values indicate soil or water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI and add it to the loaded dataset\n",
    "ds_s2_keep[\"NDVI\"] = (ds_s2_keep.nir_1 - ds_s2_keep.red)/(ds_s2_keep.nir_1 + ds_s2_keep.red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots below show the NDVI values for the two selected timesteps used to make the true-colour images above.\n",
    "Use the plots to visually confirm whether NDVI is a suitable index for change detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the NDVI values for pixels classified as water for the two dates.\n",
    "ds_s2_keep.NDVI.isel(time=[initial_timestep, final_timestep]).plot.imshow(\n",
    "    'x', 'y', col='time', cmap='RdYlGn', vmin=0, vmax=1, figsize=(18, 6))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform hypothesis test\n",
    "While it is possible to visually detect change between the `2018-08-20` and `2019-09-04` timesteps, it is important to consider how to rigorously check for both positive change in the NDVI (afforestation) and negative change in the NDVI (deforestation).\n",
    "\n",
    "This can be done through hypothesis testing.\n",
    "In this case, \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{null hypothesis } (H_0) &: \\text{no change occurred,} \\\\\n",
    "\\text{alternative hypothesis } (H_1) &: \\text{some change occurred.}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The hypothesis test will indicate where there is evidence for rejecting the null hypothesis.\n",
    "From this, we may identify areas of signficant change, according to a given significance level (covered in more detail below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make samples\n",
    "\n",
    "To perform the test, the total sample will be split in two: a `baseline` sample and a `postbaseline` sample, which respectively contain the data before and after the `time_baseline` date.\n",
    "Then, we can test for a difference in the average NDVI between the samples for each pixel in the sample.\n",
    "\n",
    "The samples are made by selecting the `NDVI` band from the dataset and filtering it based on whether it was observed before or after the `time_baseline` date.\n",
    "The number of observations in each sample will be printed.\n",
    "If one sample is much larger than the other, consider changing the `time_baseline` parameter in the \"Analysis parameters\" cell, and then re-run this cell.\n",
    "Coordinates are recorded for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make samples\n",
    "baseline_sample = ds_s2_keep.NDVI.sel(time=ds_s2_keep['time']<=np.datetime64(time_baseline))\n",
    "print(f\"Number of observations in baseline sample: {len(baseline_sample.time)}\")\n",
    "\n",
    "postbaseline_sample = ds_s2_keep.NDVI.sel(time=ds_s2_keep['time']>np.datetime64(time_baseline))\n",
    "print(f\"Number of observations in postbaseline sample: {len(postbaseline_sample.time)}\")\n",
    "\n",
    "# Record coodrinates for reconstructing xarray objects\n",
    "sample_lat_coords = ds_s2.coords['y']\n",
    "sample_lon_coords = ds_s2.coords['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for change\n",
    "To look for evidence that the average NDVI has changed between the two samples (either positively or negatively), we use Welch's t-test.\n",
    "This is used to test the hypothesis that two populations have equal averages.\n",
    "In this case, the populations are the area of interest before and after the `time_baseline` date, and the average being tested is the average NDVI.\n",
    "Welch's *t*-test is used (as opposed to Student's *t*-test) because the two samples in the study may not necessarily have equal variances. \n",
    "\n",
    "The test is run using the Scipy package's statistcs library, which provides the `ttest_ind` function for running *t*-tests. \n",
    "Setting `equal_var=False` means that the function will run Welch's *t*-test.\n",
    "The function returns the *t*-statistic and *p*-value for each pixel after testing the difference in the average NDVI.\n",
    "These are stored as `t_stat` and `p_val` inside the `t_test` dataset for use in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the t-test on the postbaseline and baseline samples\n",
    "tstat, p_tstat = stats.ttest_ind(\n",
    "    postbaseline_sample.values,\n",
    "    baseline_sample.values,\n",
    "    equal_var=False,\n",
    "    nan_policy='omit',\n",
    ")\n",
    "\n",
    "# Convert results to an xarray for further analysis\n",
    "t_test = xr.Dataset(\n",
    "    {\n",
    "        't_stat': (['y', 'x'], tstat),\n",
    "        'p_val': (['y', 'x'], p_tstat)\n",
    "    },\n",
    "    coords={\n",
    "        'x': (['x'], sample_lon_coords.values),\n",
    "        'y': (['y'], sample_lat_coords.values)\n",
    "    }, \n",
    "    attrs={\n",
    "        'crs': 'EPSG:3577',\n",
    "    })\n",
    "\n",
    "print(t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise change\n",
    "From the test, we're interested in two conditions: whether the change is significant (rejection of the null hypothesis) and whether the change was positive (afforestation) or negative (deforestation).\n",
    "\n",
    "The null hypothesis can be rejected if the $p$-value (`p_val`) is less than the chosen significance level, which is set as `sig_level = 0.05` for this analysis.\n",
    "If the null hypothesis is rejected, the pixel will be classified as having undergone significant change.\n",
    "\n",
    "The direction of the change can be inferred from the difference in the average NDVI of each sample, which is calculated as $$\\text{diff mean} = \\text{mean(post baseline)} - \\text{mean(baseline)}.$$\n",
    "This means that:\n",
    "\n",
    "* if the average NDVI for a given pixel is **higher** in the `post baseline` sample compared to the `baseline` sample, then `diff_mean` for that pixel will be **positive**.\n",
    "* if the average NDVI for a given pixel is **lower** in the `post baseline` sample compared to the `baseline` sample, then `diff_mean` for that pixel will be **negative**.\n",
    "\n",
    "Run the cell below to first plot the difference in the mean between the two samples, then plot only the differences that were marked as signficant. \n",
    "**Positive change is shown in blue and negative change is shown in red.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the significance level\n",
    "sig_level = 0.05\n",
    "\n",
    "# Plot any difference in the mean\n",
    "diff_mean = postbaseline_sample.mean(dim=['time']) - baseline_sample.mean(dim=['time'])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "diff_mean.plot(cmap='RdBu')\n",
    "ax.set_title('Any difference in the mean')\n",
    "plt.show()\n",
    "\n",
    "# Plot any difference in the mean classified as significant\n",
    "sig_diff_mean = postbaseline_sample.mean(dim=['time']).where(t_test.p_val < sig_level) - baseline_sample.mean(dim=['time']).where(t_test.p_val < sig_level)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "sig_diff_mean.plot(cmap='RdBu')\n",
    "ax.set_title('Statistically significant difference in the mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing conclusions\n",
    "Here are some questions to think about:\n",
    "\n",
    "* What has happened in the forest over the time covered by the dataset?\n",
    "* Were there any statistically significant changes that the test found that you didn't see in the true-colour images? \n",
    "* What kind of activities/events might explain the significant changes?\n",
    "* What kind of activities/events might explain non-significant changes?\n",
    "* What other information might you need to draw conclusions about the cause of the statistically significant changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the data\n",
    "To explore the data further in a desktop GIS program, the data can be output as a GeoTIFF. \n",
    "The `diff_mean` product will be saved as \"ttest_diff_mean.tif\", and the `sig_diff_mean` product will be saved as \"ttest_sig_diff_mean.tif\".\n",
    "These files can be downloaded from the file explorer to the left of this window ([see these instructions](https://jupyterlab.readthedocs.io/en/stable/user/files.html#uploading-and-downloading))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cog(geo_im=diff_mean, fname=\"ttest_diff_mean.tif\", overwrite=True)\n",
    "write_cog(geo_im=sig_diff_mean, fname=\"ttest_sig_diff_mean.tif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "When you are done, return to the \"Analysis parameters\" section, modify some values (e.g. `latitude`, `longitude`, `time` or `time_baseline`) and re-run the analysis.\n",
    "You can use the interactive map in the \"View the selected location\" section to find new central latitude and longitude values by panning and zooming, and then clicking on the area you wish to extract location values for.\n",
    "You can also use Google maps to search for a location you know, then return the latitude and longitude values by clicking the map.\n",
    "\n",
    "If you're going to change the location, you'll need to make sure Sentinel-2 data is available for the new location, which you can check at the [EASI CSIRO Asia Explorer](http://explorer.asia.easi-eo.solutions/products/s2_l2a).\n",
    "Use the drop-down menu to check Sentinel-2a and Sentinel-2b (`s2_l2a`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
