{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# USGS Landsat collection 2 using datacube <img align=\"right\" src=\"../resources/csiro_easi_logo.png\">\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "- [Setup (dask, imports, query)](#Setup)\n",
    "- [Product definition (measurements, flags)](#Product-definition)\n",
    "- [Quality layer (mask)](#Quality-layer)\n",
    "- [Scaling and nodata](#Scaling-and-nodata)\n",
    "- [Visualisation](#Visualisation)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook shows how to search the search the local ODC database index of Landsat data and import selected items into an xarray Dataset. Scaling and pixel quality masking are applied using datacube functions.\n",
    "\n",
    "## USGS Landsat\n",
    "\n",
    "Landsat-5, 7, 8 and 9 [collection 2](https://www.usgs.gov/landsat-missions/landsat-collection-2) products are managed by USGS. USGS make Landsat data available via number of services, including:\n",
    "\n",
    "- [Earth Explorer](https://earthexplorer.usgs.gov) - USGS data browser and viewer\n",
    "- [Landsat Look](https://landsatlook.usgs.gov/stac-browser/collection02) - Landsat scene browser (STAC)\n",
    "- [AWS OpenData](https://registry.opendata.aws/usgs-landsat) - Cloud-hosted data (STAC)\n",
    "- [ESPA](https://espa.cr.usgs.gov) - USGS On-demand processing\n",
    "- Google Earth Engine\n",
    "- Microsoft Planetary Computer\n",
    "\n",
    "#### Data source and documentation\n",
    "\n",
    "[Surface Reflectance](https://www.usgs.gov/landsat-missions/landsat-collection-2-level-2-science-products), [Surface Temperature](https://www.usgs.gov/landsat-missions/landsat-collection-2-level-2-science-products) and [Level-1 (top of atmosphere)](https://www.usgs.gov/landsat-missions/landsat-collection-2-level-1-data) products for each of [Landsat-5, 7, 8 and 9](https://www.usgs.gov/landsat-missions/landsat-satellite-missions) are available.\n",
    "\n",
    "## Open Data Cube\n",
    "\n",
    "EASI Asia ODC product names ([Explorer](http://explorer.asia.easi-eo.solutions/products)):\n",
    "| Name | Product | Information\n",
    "|--|--|--|\n",
    "| USGS Landsat surface reflectance | landsat5_c2l2_sr | Landsat 5 Collection 2 Level-2 Surface Reflectance Product. 30m UTM based projection |\n",
    "| | landsat7_c2l2_sr | Landsat 7 USGS Collection 2 Surface Reflectance, processed using LEDAPS. 30m UTM based projection |\n",
    "| | landsat8_c2l2_sr | Landsat 8 Collection 2 Surface Reflectance, processed using LaSRC. 30m UTM based projection |\n",
    "| | landsat9_c2l2_sr | Landsat 9 Collection 2 Surface Reflectance, processed using LaSRC. 30m UTM based projection |\n",
    "| USGS Landsat surface temperature | landsat5_c2l2_st | Landsat 5 Collection 2 Level-2 UTM Surface Temperature (ST) Product |\n",
    "| | landsat7_c2l2_st | Landsat 7 Collection 2 Level-2 UTM Surface Temperature (ST) Product |\n",
    "| | landsat8_c2l2_st | Landsat 8 Collection 2 Level-2 UTM Surface Temperature (ST) Product |\n",
    "| | landsat9_c2l2_st | Landsat 9 Collection 2 Level-2 UTM Surface Temperature (ST) Product |\n",
    "| USGS Landsat Level-1 (TOA) | landsat8_c2l1 | Landsat 8 Collection 2 Level-1 (top of atmosphere) |\n",
    "| | landsat9_c2l1 | Landsat 9 Collection 2 Level-1 (top of atmosphere) |\n",
    "\n",
    "#### EASI pipeline\n",
    "\n",
    "Landsat products are read from the [AWS STAC API](https://landsatlook.usgs.gov/stac-server/). The data are in COG format. Two methods are shown in this notebook, each returns an essentially equivalent `xarray Dataset`:\n",
    "1. Read from the STAC catalog (uses [odc-stac](https://github.com/opendatacube/odc-stac))\n",
    "1. Read from the `datacube` database, which has a \"cached\" copy of the scenes and metadata (uses [odc-tools](https://github.com/opendatacube/odc-tools/blob/develop/apps/dc_tools/odc/apps/dc_tools/stac_api_to_dc.py))\n",
    "\n",
    "Notes for using the AWS STAC API:\n",
    "- Requires `requester_pays = True`\n",
    "- AWS source region is `us-west-2` (consider egress and latency)\n",
    "- Use EASI `caching-proxy` settings (to help reduce egress and latency costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Data tools\n",
    "import os, sys\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Formatting options\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "# plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils import masking\n",
    "from dea_tools.plotting import display_map, rgb\n",
    "from dea_tools.datahandling import mostcommon_crs\n",
    "from odc.algo import mask_cleanup, erase_bad, to_f32\n",
    "# from odc.stac import configure_s3_access\n",
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "# EASI packages\n",
    "repo = f'{os.environ[\"HOME\"]}/eocsi-hackathon-2022'  # No easy way to get repo directory\n",
    "if repo not in sys.path: sys.path.append(repo)\n",
    "from tools.notebook_utils import xarray_object_size, initialize_dask, localcluster_dashboard\n",
    "\n",
    "# Holoviews, Datashader and Bokeh\n",
    "# import hvplot.pandas\n",
    "# import hvplot.xarray\n",
    "# import holoviews as hv\n",
    "# import panel as pn\n",
    "# import colorcet as cc\n",
    "# import cartopy.crs as ccrs\n",
    "# from datashader import reductions\n",
    "# from holoviews import opts\n",
    "# import geoviews as gv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "# hv.extension('bokeh', logo=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask local cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_s3_access(requester_pays=True)\n",
    "\n",
    "# Optional: use EASI SE Asia caching-proxy service\n",
    "# Requires patch URL functions for each of Landsat and Sentinel-2\n",
    "os.environ[\"AWS_HTTPS\"] = \"NO\"\n",
    "os.environ[\"GDAL_HTTP_PROXY\"] = \"easi-caching-proxy.caching-proxy:80\"\n",
    "print(f'Will use caching proxy at: {os.environ.get(\"GDAL_HTTP_PROXY\")}')\n",
    "\n",
    "cluster, client = initialize_dask(use_gateway=False, workers=(1,7), wait=False)\n",
    "if cluster: display(cluster)\n",
    "if cluster is None or 'LocalCluster' in str(type(cluster)): display(localcluster_dashboard(client))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vietnam - Ha Long\n",
    "latitude = (20.7, 21.1)\n",
    "longitude = (106.7, 107.2)\n",
    "time=('2020-02-01', '2020-04-01')\n",
    "\n",
    "# Fiji - blows up JHub memory due to antemeridian\n",
    "# latitude = (-17.1, -16.2)\n",
    "# longitude = (178.2, 180.0)\n",
    "# time=('2020-02-01', '2020-02-20')\n",
    "\n",
    "# PNG Milne Bay\n",
    "latitude = (-10.8, -10)\n",
    "longitude = (149.7, 150.8)  \n",
    "time=('2018-02-01', '2022-02-20')\n",
    "\n",
    "# west, south, east, north\n",
    "bbox = [longitude[0], latitude[0], longitude[1], latitude[1]]\n",
    "crs = \"epsg:3857\"\n",
    "\n",
    "display_map(longitude, latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read from the ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a datacube connection\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "# Select a product\n",
    "product = 'landsat8_c2l2_sr'\n",
    "\n",
    "# Split the query to determine the most common CRS (essentially call find_datasets())\n",
    "query = {\n",
    "    'x': longitude,    # \"x\" axis bounds\n",
    "    'y': latitude,      # \"y\" axis bounds\n",
    "    'time': time,           # Any parsable date strings\n",
    "    'measurements': ['blue', 'green', 'red', 'nir08', 'pixel_quality'], \n",
    "    'product': product,                     # Product name\n",
    "    # 'output_crs': native_crs,               # EPSG code\n",
    "    'resolution': (30, 30),                 # Target resolution\n",
    "    'group_by': 'solar_day',                # Scene ordering\n",
    "    'dask_chunks': {'x': 2048, 'y': 2048},  # Dask chunks\n",
    "    'skip_broken_datasets': True,\n",
    "}\n",
    "\n",
    "simple = {k:v for k,v in query.items() if k in ('x', 'y', 'time')}\n",
    "\n",
    "# Most common CRS\n",
    "native_crs = mostcommon_crs(dc, query['product'], simple)\n",
    "query['output_crs'] = native_crs\n",
    "print(f'Native CRS: {native_crs}')\n",
    "\n",
    "# Find datasets\n",
    "items = dc.find_datasets(product=query['product'], **simple)\n",
    "print(f\"Found: {len(items):d} datasets\")\n",
    "# display(items)\n",
    "\n",
    "# Load data\n",
    "data = dc.load(**query)\n",
    "display(xarray_object_size(data))\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply cloud masking\n",
    "\n",
    "Following [Cloud_and_pixel_quality_masking.ipynb](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks/blob/main/Frequently_used_code/Cloud_and_pixel_quality_masking.ipynb), we choose the \"cloud mask filtered\" method to remove false-positive cloud features before temporal aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_def = data.pixel_quality.attrs[\"flags_definition\"]\n",
    "flags_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_def = data.pixel_quality.attrs[\"flags_definition\"]\n",
    "\n",
    "quality_flags = dict(\n",
    "    cloud=\"high_confidence\", # True where there is cloud\n",
    "    cirrus=\"high_confidence\",# True where there is cirrus cloud\n",
    "    cloud_shadow=\"high_confidence\",# True where there is cloud shadow\n",
    ")\n",
    "\n",
    "# Set cloud_mask: True=cloud, False=non-cloud\n",
    "mask, _= masking.create_mask_value(flags_def, **quality_flags)\n",
    "\n",
    "# Add the cloud mask to our dataset\n",
    "data['cloud_mask'] = (data['pixel_quality'] & mask) != 0\n",
    "\n",
    "# Set the filters to apply. The integers refer to the number of pixels\n",
    "filters = [(\"opening\", 2),(\"dilation\", 2)]\n",
    "\n",
    "# Use the mask_cleanup function to apply the filters\n",
    "data['cloud_mask_filtered'] = mask_cleanup(data['cloud_mask'], mask_filters=filters)\n",
    "\n",
    "# erase pixels with the cloud_filtering\n",
    "clear_filtered = erase_bad(data.drop_vars(['pixel_quality', 'cloud_mask_filtered', 'cloud_mask']),\n",
    "                           data['cloud_mask_filtered'])\n",
    "\n",
    "clear_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to `float32` and set no-data values to `NaN`:\n",
    "clear_filtered = to_f32(clear_filtered)\n",
    "\n",
    "# Apply the scale and offset factors to the Landsat data\n",
    "clear_filtered = 2.75e-5 * clear_filtered - 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual median NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_filtered['ndvi'] = (clear_filtered.nir08 - clear_filtered.red)/(clear_filtered.nir08 + clear_filtered.red)\n",
    "\n",
    "annual = clear_filtered.ndvi.groupby(\"time.year\").median().persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = clear_filtered.red.groupby(\"time.year\").median().persist()\n",
    "red.plot(col=\"year\", cmap=\"YlGn\", col_wrap=4, vmin=0, vmax=1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the output summary images (slow)\n",
    "annual.plot(col=\"year\", cmap=\"YlGn\", col_wrap=4, vmin=0, vmax=1.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb(clear_filtered, bands=['red', 'green', 'blue'], col=\"time\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Drat!\n",
    "## Geoviews/Cartopy projection from epsg:32649 to PlateCarree doesn't work (works for S2 UTM)\n",
    "##\n",
    "\n",
    "# Generate a plot\n",
    "\n",
    "# options = {\n",
    "#     'title': f'{query[\"product\"]}: {layer_name}',\n",
    "#     'width': 1000,\n",
    "#     'height': 450,\n",
    "#     'aspect': 'equal',\n",
    "#     'cmap': cc.rainbow,\n",
    "#     'clim': (0, 0.05),                          # Limit the color range depending on the layer_name\n",
    "#     'colorbar': True,\n",
    "#     'tools': ['hover'],\n",
    "# }\n",
    "\n",
    "# # Set the Dataset CRS\n",
    "# plot_crs = native_crs\n",
    "# if plot_crs == 'epsg:4326':\n",
    "#     plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# # Native data and coastline overlay:\n",
    "# # - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# # TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "    \n",
    "# layer_plot = layer.hvplot.image(\n",
    "#     x = 'x', y = 'y',                        # Dataset x,y dimension names\n",
    "#     rasterize = True,                        # Use Datashader\n",
    "#     aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "#     precompute = True,                       # Datashader precomputes what it can\n",
    "#     crs = plot_crs,                          # Dataset crs\n",
    "#     projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "#     coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    "# ).options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "# # display(layer_plot)\n",
    "# # Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "# fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "# display(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
