{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat collection 2, USGS <img align=\"right\" src=\"../resources/csiro_easi_logo.png\">\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "- [Setup (dask, imports, query)](#Setup)\n",
    "- [Product definition (measurements, flags)](#Product-definition)\n",
    "- [Quality layer (mask)](#Quality-layer)\n",
    "- [Scaling and nodata](#Scaling-and-nodata)\n",
    "- [Visualisation](#Visualisation)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "\"Since 1972, the joint NASA/ U.S. Geological Survey Landsat series of Earth Observation satellites have continuously acquired images of the Earthâ€™s land surface, providing uninterrupted data to help land managers and policymakers make informed decisions about natural resources and the environment.\" https://www.usgs.gov/landsat-missions\n",
    "\n",
    "Landsat-5, 7, 8 and 9 [collection 2](https://www.usgs.gov/landsat-missions/landsat-collection-2) products are managed by USGS. USGS make Landsat data available via number of services, including:\n",
    "\n",
    "- [Earth Explorer](https://earthexplorer.usgs.gov) - USGS View and browser\n",
    "- [ESPA](https://espa.cr.usgs.gov) - USGS One-demand processing\n",
    "- [AWS (STAC)](https://registry.opendata.aws/usgs-landsat) - Cloud-hosted data with [STAC](https://stacspec.org) API\n",
    "- Google Earth Engine\n",
    "- Microsoft Planetary Computer\n",
    "\n",
    "#### Data source and documentation\n",
    "\n",
    "[Surface Reflectance](https://www.usgs.gov/landsat-missions/landsat-collection-2-level-2-science-products), [Surface Temperature](https://www.usgs.gov/landsat-missions/landsat-collection-2-level-2-science-products) and [Level-1 (top of atmosphere)](https://www.usgs.gov/landsat-missions/landsat-collection-2-level-1-data) products for each of [Landsat-5, 7, 8 and 9](https://www.usgs.gov/landsat-missions/landsat-satellite-missions) are available.\n",
    "\n",
    "EASI Asia ODC product names ([Explorer](http://explorer.asia.easi-eo.solutions/products)):\n",
    "| Name | Product | Information\n",
    "|--|--|--|\n",
    "| USGS Landsat surface reflectance | landsat5_c2l2_sr | Landsat 5 Collection 2 Level-2 Surface Reflectance Product. 30m UTM based projection |\n",
    "| | landsat7_c2l2_sr | Landsat 7 USGS Collection 2 Surface Reflectance, processed using LEDAPS. 30m UTM based projection |\n",
    "| | landsat8_c2l2_sr | Landsat 8 Collection 2 Surface Reflectance, processed using LaSRC. 30m UTM based projection |\n",
    "| | landsat9_c2l2_sr | Landsat 9 Collection 2 Surface Reflectance, processed using LaSRC. 30m UTM based projection |\n",
    "| USGS Landsat surface temperature | landsat5_c2l2_st | Landsat 5 Collection 2 Level-2 UTM Surface Temperature (ST) Product |\n",
    "| | landsat7_c2l2_st | Landsat 7 Collection 2 Level-2 UTM Surface Temperature (ST) Product |\n",
    "| | landsat8_c2l2_st | Landsat 8 Collection 2 Level-2 UTM Surface Temperature (ST) Product |\n",
    "| | landsat9_c2l2_st | Landsat 9 Collection 2 Level-2 UTM Surface Temperature (ST) Product |\n",
    "| USGS Landsat Level-1 (TOA) | landsat8_c2l1 | Landsat 8 Collection 2 Level-1 (top of atmosphere) |\n",
    "| | landsat9_c2l1 | Landsat 9 Collection 2 Level-1 (top of atmosphere) |\n",
    "\n",
    "\n",
    "#### EASI pipeline\n",
    "\n",
    "Landsat products are read from the [AWS STAC API](https://landsatlook.usgs.gov/stac-server/). The data are in COG format. Two methods are shown in this notebook, each returns an essentially equivalent `xarray Dataset`:\n",
    "1. Read from the STAC catalog (uses [odc-stac](https://github.com/opendatacube/odc-stac))\n",
    "1. Read from the `datacube` database, which has a \"cached\" copy of the scenes and metadata (uses [odc-tools](https://github.com/opendatacube/odc-tools/blob/develop/apps/dc_tools/odc/apps/dc_tools/stac_api_to_dc.py))\n",
    "\n",
    "Notes for using the AWS STAC API:\n",
    "- Requires `requester_pays = True`\n",
    "- AWS source region is `us-west-2` (consider egress and latency)\n",
    "- Use EASI `caching-proxy` settings (to help reduce egress and latency costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Data tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Formatting options\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "# plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils import masking  # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from odc.algo import enum_to_bool   # https://github.com/opendatacube/odc-tools/blob/develop/libs/algo/odc/algo/_masking.py\n",
    "from datacube.utils.aws import configure_s3_access\n",
    "\n",
    "# Notebook helper tools (in dea_tools or in this repo)\n",
    "import sys\n",
    "from os import environ\n",
    "repo = f'{environ[\"HOME\"]}/eocsi-hackathon-2022'  # No easy way to get repo directory\n",
    "if repo not in sys.path: sys.path.append(repo)\n",
    "from tools.notebook_utils import xarray_object_size\n",
    "try:\n",
    "    from dea_tools.plotting import display_map, rgb\n",
    "    from dea_tools.datahandling import mostcommon_crs\n",
    "except ImportError:\n",
    "    # Local copy of selected dea_tools\n",
    "    from tools.datacube_utils import display_map, mostcommon_crs\n",
    "    rgb = None  # Not copied or adapted yet\n",
    "\n",
    "# Holoviews, Datashader and Bokeh\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "import cartopy.crs as ccrs\n",
    "from datashader import reductions\n",
    "from holoviews import opts\n",
    "# import geoviews as gv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "hv.extension('bokeh', logo=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to the ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a datacube connection\n",
    "dc = datacube.Datacube()\n",
    "\n",
    "# Access AWS \"requester-pays\" buckets\n",
    "configure_s3_access(aws_unsigned=False, requester_pays=True)\n",
    "\n",
    "# Use EASI caching-proxy (applies to selected source buckets)\n",
    "environ[\"AWS_HTTPS\"] = \"NO\"\n",
    "environ[\"GDAL_HTTP_PROXY\"] = \"easi-caching-proxy.caching-proxy:80\"\n",
    "print(f'Will use caching proxy at: {environ.get(\"GDAL_HTTP_PROXY\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vietnam - Ha Long\n",
    "latitude = (20.7, 21.1)\n",
    "longitude = (106.7, 107.2)\n",
    "time=('2020-02-01', '2020-04-01')\n",
    "display_map(longitude, latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read from the STAC catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read from the ODC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a product\n",
    "product = 'landsat8_c2l2_sr'\n",
    "\n",
    "# Split the query to determine the most common CRS (essentially call find_datasets())\n",
    "query = {\n",
    "    'x': longitude,    # \"x\" axis bounds\n",
    "    'y': latitude,      # \"y\" axis bounds\n",
    "    'time': time,           # Any parsable date strings\n",
    "}\n",
    "\n",
    "# Most common CRS\n",
    "# dea_tools: ValueError if query does not return datasets\n",
    "native_crs = mostcommon_crs(dc, product, query)\n",
    "print(f'Native CRS: {native_crs}')\n",
    "\n",
    "query.update({\n",
    "    'product': product,                     # Product name\n",
    "    'output_crs': native_crs,               # EPSG code\n",
    "    'resolution': (30, 30),                # Target resolution\n",
    "    'group_by': 'solar_day',                # Scene ordering\n",
    "    # 'dask_chunks': {'x': 2048, 'y': 2048},  # Dask chunks\n",
    "})\n",
    "\n",
    "# Load data\n",
    "data = dc.load(**query)\n",
    "display(xarray_object_size(data))\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Filter Datasets prior to Load\n",
    "\n",
    "# For example, to load only Tier 1 (best quality) datasets and exclude Tier 2 (good quality).\n",
    "# See https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collection-1 for a description of Landsat processing Tiers.\n",
    "\n",
    "# 1. Remove load parameters from query object\n",
    "# Borrowed from https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/Tools/dea_tools/datahandling.py\n",
    "\n",
    "# non_load_query = datacube_utils.dc_query_only(**query)\n",
    "# dataset_list = dc.find_datasets(**non_load_query)\n",
    "\n",
    "# 2. Check your query has results\n",
    "# Borrowed from https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/Tools/dea_tools/datahandling.py\n",
    "\n",
    "# if len(dataset_list) == 0:\n",
    "#    print(\"No data available for query: ensure that \"\n",
    "#          \"the products specified have data for the \"\n",
    "#          \"time and location requested\")\n",
    "\n",
    "# 3. Check what details are available in each dataset\n",
    "# See https://github.com/opendatacube/datacube-core/blob/develop/datacube/model/__init__.py, class Dataset\n",
    "# display(datasets[0].__dict__)\n",
    "\n",
    "# 4. Filter based on property of interest\n",
    "# For Landsat, the Tier label is available in the 'landsat:collection_category' property\n",
    "\n",
    "# dataset_list = [ds for ds in dataset_list if ds.metadata_doc['properties']['landsat:collection_category'] == 'T1']\n",
    "# if len(dataset_list) == 0:\n",
    "#    print(\"No data available after filtering\")\n",
    "\n",
    "# 5. Update query object for next cell\n",
    "# 'datasets' will used instead of the standard database lookup\n",
    "\n",
    "# query['datasets'] = dataset_list\n",
    "# query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = dc.load(**query)\n",
    "\n",
    "notebook_utils.heading(notebook_utils.xarray_object_size(data))\n",
    "display(data)\n",
    "\n",
    "# Calculate valid (not nodata) masks for each layer\n",
    "valid_mask = masking.valid_data_mask(data)\n",
    "notebook_utils.heading('Valid data masks for each variable')\n",
    "display(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product definition\n",
    "\n",
    "Display the measurement definitions for the selected product.\n",
    "\n",
    "Use `list_measurements` to show the details for a product, and `masking.describe_variable_flags` to show the flag definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement definitions for the selected product\n",
    "measurement_info = dc.list_measurements().loc[query['product']]\n",
    "notebook_utils.heading(f'Measurement table for product: {query[\"product\"]}')\n",
    "notebook_utils.display_table(measurement_info)  # Default pandas table display. Some rows or columns may be abbreviated\n",
    "\n",
    "# Separate lists of measurement names and flag names\n",
    "measurement_names = measurement_info[ pd.isnull(measurement_info.flags_definition)].index\n",
    "flag_names        = measurement_info[pd.notnull(measurement_info.flags_definition)].index\n",
    "\n",
    "notebook_utils.heading('Selected Measurement and Flag names')\n",
    "notebook_utils.display_table(pd.DataFrame({\n",
    "    'group': ['Measurement names', 'Flag names'],\n",
    "    'names': [', '.join(measurement_names), ', '.join(flag_names)]\n",
    "}))\n",
    "\n",
    "# Flag definitions\n",
    "for flag in flag_names:\n",
    "    notebook_utils.heading(f'Flag definition table for flag name: {flag}')\n",
    "    notebook_utils.display_table(masking.describe_variable_flags(data[flag]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make L2_FLAGS image\n",
    "flag_name = 'pixel_qa'\n",
    "flag_data = data[[flag_name]].where(valid_mask[flag_name]).persist()   # Dataset\n",
    "display(flag_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Drat!\n",
    "## Geoviews/Cartopy projection from epsg:32649 to PlateCarree doesn't work (works for S2 UTM)\n",
    "##\n",
    "\n",
    "# These options manipulate the color map and colorbar to show the categories for this product\n",
    "options = {\n",
    "    'title': f'Flag data for: {query[\"product\"]} ({flag_name})',\n",
    "    'cmap': cc.rainbow,\n",
    "    'colorbar': True,\n",
    "    'width': 700,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "\n",
    "quality_plot = flag_data.hvplot.image(\n",
    "    x = 'x', y = 'y',         # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mode(),          # Datashader selects mode value, requires 'hv.Image'\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                          # Dataset CRS\n",
    "    projection = ccrs.PlateCarree(),         # Output Projection (ccrs.PlateCarree() when coastline=True)\n",
    "    coastline = '10m',                       # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist()\n",
    "\n",
    "# display(quality_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(quality_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask layer\n",
    "\n",
    "# \"L3 Mask Default\"\n",
    "good_pixel_flags = {\n",
    "    'snow': 'no_snow',                    # 'no_snow', 'snow'\n",
    "#     'clear': 'clear_land',                # 'no_clear_land', 'clear_land'\n",
    "    'cloud': 'no_cloud',                  # 'no_cloud', 'cloud'\n",
    "#     'water': 'water',                     # 'no_water', 'water'\n",
    "    'nodata': False,                      # False, True\n",
    "    'cloud_shadow': 'no_cloud_shadow',    # 'no_cloud_shadow', 'cloud_shadow'\n",
    "#     'cloud_confidence': 'medium',         # 'none', 'low', 'medium', 'high'\n",
    "#     'cirrus_confidence': 'medium',        # 'none', 'low', 'medium', 'high'\n",
    "#     'terrain_occlusion': 'no_occlusion',  # 'no_occlusion', 'occlusion'\n",
    "}\n",
    "\n",
    "good_pixel_mask = masking.make_mask(data[flag_name], **good_pixel_flags)  # -> bool array\n",
    "display(good_pixel_mask)  # Type: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaling\n",
    "\n",
    "# usgs_espa_ls8c1_sr, usgs_espa_ls8c1_ar\n",
    "scale = 0.0001\n",
    "offset = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a layer and apply masking and scaling, then persist in dask\n",
    "\n",
    "layer_name = 'nir'\n",
    "\n",
    "# Apply valid mask and good pixel mask\n",
    "layer = data[[layer_name]].where(valid_mask[layer_name] & good_pixel_mask) * scale + offset\n",
    "layer = layer.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Drat!\n",
    "## Geoviews/Cartopy projection from epsg:32649 to PlateCarree doesn't work (works for S2 UTM)\n",
    "##\n",
    "\n",
    "# Generate a plot\n",
    "\n",
    "options = {\n",
    "    'title': f'{query[\"product\"]}: {layer_name}',\n",
    "    'width': 1000,\n",
    "    'height': 450,\n",
    "    'aspect': 'equal',\n",
    "    'cmap': cc.rainbow,\n",
    "    'clim': (0, 0.05),                          # Limit the color range depending on the layer_name\n",
    "    'colorbar': True,\n",
    "    'tools': ['hover'],\n",
    "}\n",
    "\n",
    "# Set the Dataset CRS\n",
    "plot_crs = native_crs\n",
    "if plot_crs == 'epsg:4326':\n",
    "    plot_crs = ccrs.PlateCarree()\n",
    "\n",
    "\n",
    "# Native data and coastline overlay:\n",
    "# - Comment `crs`, `projection`, `coastline` to plot in native_crs coords\n",
    "# TODO: Update the axis labels to 'longitude', 'latitude' if `coastline` is used\n",
    "    \n",
    "layer_plot = layer.hvplot.image(\n",
    "    x = 'x', y = 'y',                        # Dataset x,y dimension names\n",
    "    rasterize = True,                        # Use Datashader\n",
    "    aggregator = reductions.mean(),          # Datashader selects mean value\n",
    "    precompute = True,                       # Datashader precomputes what it can\n",
    "    crs = plot_crs,                          # Dataset crs\n",
    "    projection = ccrs.PlateCarree(),         # Output projection (use ccrs.PlateCarree() when coastline=True)\n",
    "    coastline='10m',                         # Coastline = '10m'/'50m'/'110m'\n",
    ").options(opts.Image(**options)).hist(bin_range = options['clim'])\n",
    "\n",
    "# display(layer_plot)\n",
    "# Optional: Change the default time slider to a dropdown list, https://stackoverflow.com/a/54912917\n",
    "fig = pn.panel(layer_plot, widgets={'time': pn.widgets.Select})  # widget_location='top_left'\n",
    "display(fig)\n",
    "\n",
    "# Good image of Sarawak: 2020-01-27 0555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "Reference material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter datasets\n",
    "\n",
    "# From load_ard()\n",
    "datasets = dc.find_datasets(product=product, **query)\n",
    "\n",
    "# Remove datasets after the Landsat 7 SLC failure, May 31 2003.\n",
    "if product in ('ga_ls7e_ard_3', 'usgs_espa_ls7c1_sr'):\n",
    "    datasets = [i for i in datasets if\n",
    "                normalise_dt(i.time.begin) <\n",
    "                datetime.datetime(2003, 5, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking and Scaling\n",
    "\n",
    "# dea-notebooks/Real_world_examples/ARD_Intercomparison/utilities/util.py\n",
    "\n",
    "ls8_USGS_cloud_pixel_qa_value = [324, 352, 368, 386, 388, 392, 400, 416, \n",
    "                                     432, 480, 864, 880, 898, 900, 904, 928, \n",
    "                                     944, 992, 1350]\n",
    "non_ls8_USGS_cloud_pixel_qa_value = [72, 96, 112, 130, 132, 136, 144, 160, \n",
    "                                         176, 224]\n",
    "    non_ls8_USGS_sr_cloud_qa_value = [2, 4, 12, 20, 34, 36, 52]\n",
    "\n",
    "mask_data = data[mask_band]\n",
    "    nodata_value = mask_data.nodata\n",
    "    nodata_cloud_value = []\n",
    "    \n",
    "    if 'usgs' in source_prod:\n",
    "        if 'ls8' in source_prod:\n",
    "            nodata_cloud_value = ls8_USGS_cloud_pixel_qa_value\n",
    "        else:\n",
    "            if mask_band == 'sr_cloud_qa':\n",
    "                nodata_cloud_value = non_ls8_USGS_sr_cloud_qa_value\n",
    "            else:\n",
    "                nodata_cloud_value = non_ls8_USGS_cloud_pixel_qa_value\n",
    "                \n",
    "        nodata_cloud_value.append(nodata_value)\n",
    "        nodata_cloud = np.isin(mask_data, nodata_cloud_value) \n",
    "        cld_free = data.where(~nodata_cloud).dropna(dim='time', how='all')\n",
    "        \n",
    "    # remove nodata for the pixel of interest\n",
    "    cld_free_valid = masking.mask_invalid_data(cld_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
